{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf307676",
   "metadata": {},
   "source": [
    "<div align=\"center>\n",
    "            <h1>\n",
    "            TUTORIAL\n",
    "            </h1>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76754d0",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    <center>\n",
    "        -- TUTORIAL --\n",
    "    </center>\n",
    "</h1>\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b328d62",
   "metadata": {},
   "source": [
    "In this notebook, we are going to have a good tour of main features, usages and how-to of the package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d7027",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e999060",
   "metadata": {},
   "source": [
    "## 1. Install\n",
    "****************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3e06f1",
   "metadata": {},
   "source": [
    "As requested we need to install the package from pypi. Depends of your internet connection, it could take 1 or 2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6cfb9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: legal_doc_processing==2.2.3 in /home/alex/ENV/lib/python3.8/site-packages (2.2.3)\n",
      "Requirement already satisfied: tensorflow in /home/alex/ENV/lib/python3.8/site-packages (from legal_doc_processing==2.2.3) (2.5.0)\n",
      "Requirement already satisfied: nltk in /home/alex/ENV/lib/python3.8/site-packages (from legal_doc_processing==2.2.3) (3.6.2)\n",
      "Requirement already satisfied: clean-text in /home/alex/ENV/lib/python3.8/site-packages (from legal_doc_processing==2.2.3) (0.4.0)\n",
      "Requirement already satisfied: spacy in /home/alex/ENV/lib/python3.8/site-packages (from legal_doc_processing==2.2.3) (3.0.6)\n",
      "Requirement already satisfied: word2vec in /home/alex/ENV/lib/python3.8/site-packages (from legal_doc_processing==2.2.3) (0.11.1)\n",
      "Requirement already satisfied: google-cloud-storage in /home/alex/ENV/lib/python3.8/site-packages (from legal_doc_processing==2.2.3) (1.38.0)\n",
      "Requirement already satisfied: dateparser in /home/alex/ENV/lib/python3.8/site-packages (from legal_doc_processing==2.2.3) (1.0.0)\n",
      "Requirement already satisfied: pandas in /home/alex/ENV/lib/python3.8/site-packages (from legal_doc_processing==2.2.3) (1.2.4)\n",
      "Requirement already satisfied: scikit-learn in /home/alex/ENV/lib/python3.8/site-packages (from legal_doc_processing==2.2.3) (0.24.2)\n",
      "Requirement already satisfied: transformers in /home/alex/ENV/lib/python3.8/site-packages (from legal_doc_processing==2.2.3) (4.6.1)\n",
      "Requirement already satisfied: ftfy<7.0,>=6.0 in /home/alex/ENV/lib/python3.8/site-packages (from clean-text->legal_doc_processing==2.2.3) (6.0.1)\n",
      "Requirement already satisfied: emoji in /home/alex/ENV/lib/python3.8/site-packages (from clean-text->legal_doc_processing==2.2.3) (1.2.0)\n",
      "Requirement already satisfied: wcwidth in /home/alex/ENV/lib/python3.8/site-packages (from ftfy<7.0,>=6.0->clean-text->legal_doc_processing==2.2.3) (0.2.5)\n",
      "Requirement already satisfied: tzlocal in /home/alex/ENV/lib/python3.8/site-packages (from dateparser->legal_doc_processing==2.2.3) (2.1)\n",
      "Requirement already satisfied: regex!=2019.02.19 in /home/alex/ENV/lib/python3.8/site-packages (from dateparser->legal_doc_processing==2.2.3) (2020.9.27)\n",
      "Requirement already satisfied: pytz in /home/alex/ENV/lib/python3.8/site-packages (from dateparser->legal_doc_processing==2.2.3) (2020.1)\n",
      "Requirement already satisfied: python-dateutil in /home/alex/ENV/lib/python3.8/site-packages (from dateparser->legal_doc_processing==2.2.3) (2.8.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /home/alex/ENV/lib/python3.8/site-packages (from google-cloud-storage->legal_doc_processing==2.2.3) (2.24.0)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.11.0 in /home/alex/ENV/lib/python3.8/site-packages (from google-cloud-storage->legal_doc_processing==2.2.3) (1.30.1)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.4.1 in /home/alex/ENV/lib/python3.8/site-packages (from google-cloud-storage->legal_doc_processing==2.2.3) (1.6.0)\n",
      "Requirement already satisfied: google-resumable-media<2.0dev,>=1.2.0 in /home/alex/ENV/lib/python3.8/site-packages (from google-cloud-storage->legal_doc_processing==2.2.3) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/alex/ENV/lib/python3.8/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage->legal_doc_processing==2.2.3) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/alex/ENV/lib/python3.8/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage->legal_doc_processing==2.2.3) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/alex/ENV/lib/python3.8/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage->legal_doc_processing==2.2.3) (1.15.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /home/alex/ENV/lib/python3.8/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage->legal_doc_processing==2.2.3) (54.1.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/alex/ENV/lib/python3.8/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage->legal_doc_processing==2.2.3) (4.7.2)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.21.0 in /home/alex/ENV/lib/python3.8/site-packages (from google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage->legal_doc_processing==2.2.3) (1.28.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /home/alex/ENV/lib/python3.8/site-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage->legal_doc_processing==2.2.3) (20.4)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /home/alex/ENV/lib/python3.8/site-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage->legal_doc_processing==2.2.3) (3.17.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /home/alex/ENV/lib/python3.8/site-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage->legal_doc_processing==2.2.3) (1.53.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /home/alex/ENV/lib/python3.8/site-packages (from google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage->legal_doc_processing==2.2.3) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /home/alex/ENV/lib/python3.8/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage->legal_doc_processing==2.2.3) (1.14.3)\n",
      "Requirement already satisfied: pycparser in /home/alex/ENV/lib/python3.8/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage->legal_doc_processing==2.2.3) (2.20)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/alex/ENV/lib/python3.8/site-packages (from packaging>=14.3->google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage->legal_doc_processing==2.2.3) (2.4.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/alex/ENV/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.11.0->google-cloud-storage->legal_doc_processing==2.2.3) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/alex/ENV/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->legal_doc_processing==2.2.3) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/alex/ENV/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->legal_doc_processing==2.2.3) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/alex/ENV/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->legal_doc_processing==2.2.3) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/alex/ENV/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->legal_doc_processing==2.2.3) (2020.6.20)\n",
      "Requirement already satisfied: tqdm in /home/alex/ENV/lib/python3.8/site-packages (from nltk->legal_doc_processing==2.2.3) (4.60.0)\n",
      "Requirement already satisfied: click in /home/alex/ENV/lib/python3.8/site-packages (from nltk->legal_doc_processing==2.2.3) (7.1.2)\n",
      "Requirement already satisfied: joblib in /home/alex/ENV/lib/python3.8/site-packages (from nltk->legal_doc_processing==2.2.3) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /home/alex/ENV/lib/python3.8/site-packages (from pandas->legal_doc_processing==2.2.3) (1.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/alex/ENV/lib/python3.8/site-packages (from scikit-learn->legal_doc_processing==2.2.3) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/alex/ENV/lib/python3.8/site-packages (from scikit-learn->legal_doc_processing==2.2.3) (1.6.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/alex/ENV/lib/python3.8/site-packages (from spacy->legal_doc_processing==2.2.3) (2.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/alex/ENV/lib/python3.8/site-packages (from spacy->legal_doc_processing==2.2.3) (3.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/alex/ENV/lib/python3.8/site-packages (from spacy->legal_doc_processing==2.2.3) (0.5.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/alex/ENV/lib/python3.8/site-packages (from spacy->legal_doc_processing==2.2.3) (0.8.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /home/alex/ENV/lib/python3.8/site-packages (from spacy->legal_doc_processing==2.2.3) (8.0.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/alex/ENV/lib/python3.8/site-packages (from spacy->legal_doc_processing==2.2.3) (2.4.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /home/alex/ENV/lib/python3.8/site-packages (from spacy->legal_doc_processing==2.2.3) (3.0.5)\n",
      "Requirement already satisfied: jinja2 in /home/alex/ENV/lib/python3.8/site-packages (from spacy->legal_doc_processing==2.2.3) (2.11.2)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /home/alex/ENV/lib/python3.8/site-packages (from spacy->legal_doc_processing==2.2.3) (1.7.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/alex/ENV/lib/python3.8/site-packages (from spacy->legal_doc_processing==2.2.3) (1.0.5)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /home/alex/ENV/lib/python3.8/site-packages (from spacy->legal_doc_processing==2.2.3) (0.3.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/alex/ENV/lib/python3.8/site-packages (from spacy->legal_doc_processing==2.2.3) (0.7.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /home/alex/ENV/lib/python3.8/site-packages (from spacy->legal_doc_processing==2.2.3) (2.0.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /home/alex/ENV/lib/python3.8/site-packages (from pathy>=0.3.5->spacy->legal_doc_processing==2.2.3) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/alex/ENV/lib/python3.8/site-packages (from jinja2->spacy->legal_doc_processing==2.2.3) (1.1.1)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /home/alex/ENV/lib/python3.8/site-packages (from tensorflow->legal_doc_processing==2.2.3) (2.5.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /home/alex/ENV/lib/python3.8/site-packages (from tensorflow->legal_doc_processing==2.2.3) (0.4.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/alex/ENV/lib/python3.8/site-packages (from tensorflow->legal_doc_processing==2.2.3) (3.1.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/alex/ENV/lib/python3.8/site-packages (from tensorflow->legal_doc_processing==2.2.3) (0.36.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /home/alex/ENV/lib/python3.8/site-packages (from tensorflow->legal_doc_processing==2.2.3) (2.5.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/alex/ENV/lib/python3.8/site-packages (from tensorflow->legal_doc_processing==2.2.3) (1.12.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/alex/ENV/lib/python3.8/site-packages (from tensorflow->legal_doc_processing==2.2.3) (0.2.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /home/alex/ENV/lib/python3.8/site-packages (from tensorflow->legal_doc_processing==2.2.3) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in /home/alex/ENV/lib/python3.8/site-packages (from tensorflow->legal_doc_processing==2.2.3) (1.34.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/alex/ENV/lib/python3.8/site-packages (from tensorflow->legal_doc_processing==2.2.3) (1.12)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/alex/ENV/lib/python3.8/site-packages (from tensorflow->legal_doc_processing==2.2.3) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/alex/ENV/lib/python3.8/site-packages (from tensorflow->legal_doc_processing==2.2.3) (3.3.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/alex/ENV/lib/python3.8/site-packages (from tensorflow->legal_doc_processing==2.2.3) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/alex/ENV/lib/python3.8/site-packages (from tensorflow->legal_doc_processing==2.2.3) (3.7.4.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/alex/ENV/lib/python3.8/site-packages (from tensorflow->legal_doc_processing==2.2.3) (0.12.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/alex/ENV/lib/python3.8/site-packages (from tensorflow->legal_doc_processing==2.2.3) (1.1.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/alex/ENV/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->legal_doc_processing==2.2.3) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/alex/ENV/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->legal_doc_processing==2.2.3) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/alex/ENV/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->legal_doc_processing==2.2.3) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/alex/ENV/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->legal_doc_processing==2.2.3) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/alex/ENV/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->legal_doc_processing==2.2.3) (0.4.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/alex/ENV/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->legal_doc_processing==2.2.3) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/alex/ENV/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->legal_doc_processing==2.2.3) (3.1.1)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /home/alex/ENV/lib/python3.8/site-packages (from transformers->legal_doc_processing==2.2.3) (0.0.8)\n",
      "Requirement already satisfied: sacremoses in /home/alex/ENV/lib/python3.8/site-packages (from transformers->legal_doc_processing==2.2.3) (0.0.45)\n",
      "Requirement already satisfied: filelock in /home/alex/ENV/lib/python3.8/site-packages (from transformers->legal_doc_processing==2.2.3) (3.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/alex/ENV/lib/python3.8/site-packages (from transformers->legal_doc_processing==2.2.3) (0.10.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install legal_doc_processing==2.2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead64e83",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## 2. package integrity checks and third party downloads\n",
    "************\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e000a61c",
   "metadata": {},
   "source": [
    "As we will use major NLP librairies, we need to download data collections and mandory web assets such as NLTK stop words, scapy or transformers models or tensorflow/pyTorch assets. It can take 1/2 minutes (depends of your web connection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45ad7608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PressRelease(source:cftc, {'cooperation_credit': '', 'court': 'U.S. Dis', 'currency': 'USD', 'decision_date': '2015-01-', 'extracted_sanctions': 'none of ', 'extracted_violations': 'Defendan', 'folder': '-- DUMMY', 'judge': 'Marcia M', 'monitor': '0', 'nature_de_sanction': 'none of ', 'nature_of_violations': '', 'reference': '-- DUMMY', 'extracted_authorities': 'U.S. Dis', 'type': 'Order', 'justice_type': 'U.S. - C', 'defendant': 'Chawalit', 'country_of_violation': 'United S', 'penalty_details': '', 'monetary_sanction': '1000000', 'compliance_obligations': ''}, pipe/spacy:OK/OK"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from legal_doc_processing import boot\n",
    "boot.boot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887588c7",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## 3. Understand bascic package structure\n",
    "********************\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9641ca1e",
   "metadata": {},
   "source": [
    "There is 3 main modules in legal-doc-processing : \n",
    "- legal_doc for LegalDoc objects ie order, complaint, etc etc all kinds of official documents\n",
    "- press_release for PressRelease objects for legal press release related to each case\n",
    "- decision for both LegalDoc and PressRelease documents. The Decision object is able to read both legal document and press release, make prediction from both documents and merge/clean predictions of both documents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca37cf0",
   "metadata": {},
   "source": [
    "so you can :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc575361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from legal_doc_processing import legal_doc # import legal document module\n",
    "from legal_doc_processing import press_release # import press release module\n",
    "from legal_doc_processing import decision # import decision module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4decd0b",
   "metadata": {},
   "source": [
    "\n",
    "each package has its own Object : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4167d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"press_release.PressRelease : {press_release.PressRelease} \\n\")\n",
    "print(f\"press_release.__doc__ : {press_release.__doc__} \\n\")\n",
    "print(f\"press_release.__dict__ : {press_release.__dict__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bea1ae",
   "metadata": {},
   "source": [
    "\n",
    "as consequence it is recommanded to use the import method : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62ef116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from legal_doc_processing import press_release as pr\n",
    "\n",
    "print(pr.PressRelease)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d47fc9",
   "metadata": {},
   "source": [
    "LegalDoc, PressRelease and Decision are inheritance of The Base class. You can consider The Base class is an\n",
    "as an abstraction of 3 others objecst."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef866361",
   "metadata": {},
   "source": [
    "Of course you can call this class, even if you will not mainuplate it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b912cc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from legal_doc_processing.base.base import Base\n",
    "\n",
    "print(Base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2d553d",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## 4 Object instanciation\n",
    "*****************\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66841684",
   "metadata": {},
   "source": [
    "youn can init an object in 3 ways.: \n",
    "- given a string\n",
    "- given a text file path\n",
    "- give an url\n",
    "\n",
    "this three methods are onboarded feature form the package: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dfa691",
   "metadata": {},
   "source": [
    "### 4.1 with a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5eaf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.PressRelease\n",
    "# or \n",
    "pr.from_text\n",
    "\n",
    "print(pr.PressRelease)\n",
    "print(pr.from_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f1801e",
   "metadata": {},
   "source": [
    "### 4.2 with a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc84f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.from_file\n",
    "print(pr.from_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad7881b",
   "metadata": {},
   "source": [
    "### 4.3 with an url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb463fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pr.from_url\n",
    "print(pr.from_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f513a467",
   "metadata": {},
   "source": [
    "We are going to initate  an object directly form web.\n",
    "First we need an url, and then we need the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd11c36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = \"https://storage.googleapis.com/theolex_documents_processing/cftc/text/7100-15/press-release.txt\"\n",
    "source = \"cftc\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfc8fdc",
   "metadata": {},
   "source": [
    "then we can instantiate our object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb0fb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "press = pr.from_url(url=url, source=source)\n",
    "\n",
    "print(press)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2817e46",
   "metadata": {},
   "source": [
    "as we can see, the object take between 0.3 and 1 seconds to instatialte.\n",
    "it is due to NLP complex methods to preporcess and restructure the document.\n",
    "\n",
    "to so for each object, we need to initiate complex object such as spacy instance, transformers instance etc etc.\n",
    "\n",
    "in our case, jsut for one object it is not a problem but suposed we have 1000 document to handle ? \n",
    "\n",
    "\n",
    "There is of course a solution : instaicate spacy and transformers object outside our PressRelease object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34299d8f",
   "metadata": {},
   "source": [
    "### 4.4 instanciate 100 objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb53d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from legal_doc_processing.utils import get_pipeline, get_spacy\n",
    "\n",
    "%time nlspa = get_spacy()\n",
    "%time nlpipe=get_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6f9a90",
   "metadata": {},
   "source": [
    "as we can see  nlpipe needs more than 1 sec to instanciate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7805c7",
   "metadata": {},
   "source": [
    "now we can easy loop on 100 objects in a very fast way "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10561ae0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "txt = requests.get(url).text\n",
    "txt_list = [txt for i in range(10)]\n",
    "\n",
    "make_press = lambda i : pr.PressRelease(i, source=source, nlspa=nlspa, nlpipe = nlpipe)\n",
    "%time press_list = [make_press(i) for i in txt_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b1f323",
   "metadata": {},
   "source": [
    "### 4.4 main attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef2215b",
   "metadata": {},
   "source": [
    "lets have a tour of this objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c753d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "press = press_list[0]\n",
    "print(f\"press : {press} \\n\")\n",
    "\n",
    "print(f\"press.__doc__ : {press.__doc__ } \\n\" )\n",
    "\n",
    "print(f\"press.__dict__.keys() : {press.__dict__.keys() } \\n\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8807c40",
   "metadata": {},
   "source": [
    "we can find some basics attributes such as : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ff05f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basic_attrs = ['obj_name', 'juridiction', 'source', 'raw_text', ]\n",
    "    \n",
    "strize = lambda attr :  str(getattr(press, attr))[:200].replace('\\n', '/n')\n",
    "for attr in  basic_attrs : \n",
    "    print(f\"{attr.ljust(20)} : {strize(attr)}\")\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d6226d",
   "metadata": {},
   "source": [
    "we can find some specific attrs relative to the document structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d70776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basic_attrs = ['date', 'h1', 'header', 'content', 'struct_content', 'abstract', 'end']\n",
    "    \n",
    "strize = lambda attr :  str(getattr(press, attr))[:200].replace('\\n', '/n')\n",
    "for attr in  basic_attrs : \n",
    "    print(f\"{attr.ljust(20)} : {strize(attr)}\")\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9428f66",
   "metadata": {},
   "source": [
    "and even more interessant we can find a list of data points in : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc24bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint \n",
    "\n",
    "pprint.pprint(press.feature_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778ca59f",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## 5. Predictions\n",
    "**********************\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb91cf7",
   "metadata": {},
   "source": [
    "### 5.1 specific predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f35e87",
   "metadata": {},
   "source": [
    "\n",
    "you can now make predictions : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f11257",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time defendant =  press.predict(\"defendant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4024e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "we have to ways of getting a predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac82227",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 5.2 raw vs final predicstions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69e622a",
   "metadata": {},
   "source": [
    "fist one is the result of the prediction wich is a list of tupples with answer, score suct as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0c8fa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(defendants)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b000c9e",
   "metadata": {},
   "source": [
    "you can acces to the same object with the sp√©cial _feature_dict attribute and underscored feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fb0305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(press._feature_dict[\"_defendant\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b653c3fd",
   "metadata": {},
   "source": [
    "or if you want a more usable object , you acces to the str readble answer with the feature_dict argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41700f5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(press.feature_dict[\"defendant\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca53a69",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 5.3 make all predictions at once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07124a82",
   "metadata": {},
   "source": [
    "and of course you have a predic_all and predict(\"all\") methods to make all predictions in once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d21f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _ = press.predict_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ba564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(press.feature_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d586e0e3",
   "metadata": {},
   "source": [
    "or if you want the raw value of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf134af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(press._feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cc89b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64412f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
